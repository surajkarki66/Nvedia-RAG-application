{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Questions To Think About:**\n",
        "\n",
        "- Would there ever be a use for a single-module variant of the running state chain that is not constantly querying the environment for input?\n",
        "- You may notice that the JSON prediction is actually working pretty well. It might not always work so well depending on the questions and the JSON format complexity. What kinds of issues do you expect to encounter in this regard?\n",
        "- What kinds of approaches can you think of completely swapping prompts as part of the running state chain?"
      ],
      "metadata": {
        "id": "_5gLNflLtk9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Environment Setup:**"
      ],
      "metadata": {
        "id": "jpeXk7a31IdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Necessary for Colab, not necessary for course environment\n",
        "%pip install -q langchain langchain-nvidia-ai-endpoints gradio\n",
        "\n",
        "from functools import partial\n",
        "from rich.console import Console\n",
        "from rich.style import Style\n",
        "from rich.theme import Theme\n",
        "\n",
        "console = Console()\n",
        "base_style = Style(color=\"#76B900\", bold=True)\n",
        "pprint = partial(console.print, style=base_style)"
      ],
      "metadata": {
        "id": "vA_YFnYj1LZS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"NVIDIA_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "i2huhDdeCD2Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "ChatNVIDIA.get_available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st7kdho83g1B",
        "outputId": "1f6ff5cf-b838-40de-ed85-e28c55698539"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(id='microsoft/phi-3-small-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-small-128k-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='nvidia/llama3-chatqa-1.5-70b', model_type='qa', client='ChatNVIDIA', endpoint=None, aliases=['ai-chatqa-1.5-70b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='01-ai/yi-large', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-yi-large'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/gemma-2-2b-it', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-medium-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-medium-128k-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='writer/palmyra-fin-70b-32k', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=False, supports_structured_output=True, base_model=None),\n",
              " Model(id='writer/palmyra-med-70b-32k', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-palmyra-med-70b-32k'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-mini-128k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-mini'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='nvidia/nemotron-4-340b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['qa-nemotron-4-340b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='deepseek-ai/deepseek-coder-6.7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-deepseek-coder-6_7b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/llama3-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama3-70b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/gemma-2b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2b', 'playground_gemma_2b', 'gemma_2b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-vision-128k-instruct', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/microsoft/phi-3-vision-128k-instruct', aliases=['ai-phi-3-vision-128k-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='nv-mistralai/mistral-nemo-12b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None),\n",
              " Model(id='nvidia/usdcode-llama3-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-medium-4k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-medium-4k-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/codellama-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codellama-70b', 'playground_llama2_code_70b', 'llama2_code_70b', 'playground_llama2_code_34b', 'llama2_code_34b', 'playground_llama2_code_13b', 'llama2_code_13b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='databricks/dbrx-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-dbrx-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='snowflake/arctic', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-arctic'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/llama-3.1-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None),\n",
              " Model(id='adept/fuyu-8b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/adept/fuyu-8b', aliases=['ai-fuyu-8b', 'playground_fuyu_8b', 'fuyu_8b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mediatek/breeze-7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-breeze-7b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='aisingapore/sea-lion-7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-sea-lion-7b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='nvidia/llama3-chatqa-1.5-8b', model_type='qa', client='ChatNVIDIA', endpoint=None, aliases=['ai-chatqa-1.5-8b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-small-8k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-small-8k-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mistral-7b-instruct-v0.3', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-7b-instruct-v03'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/kosmos-2', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/microsoft/kosmos-2', aliases=['ai-microsoft-kosmos-2', 'playground_kosmos_2', 'kosmos_2'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='ibm/granite-34b-code-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-granite-34b-code-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='upstage/solar-10.7b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-solar-10_7b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/gemma-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-7b', 'playground_gemma_7b', 'gemma_7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/gemma-2-27b-it', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2-27b-it'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/codestral-22b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codestral-22b-instruct-v01'], supports_tools=False, supports_structured_output=True, base_model=None),\n",
              " Model(id='meta/llama-3.1-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None),\n",
              " Model(id='google/paligemma', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/google/paligemma', aliases=['ai-google-paligemma'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='microsoft/phi-3-mini-4k-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-phi-3-mini-4k', 'playground_phi2', 'phi2'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='ibm/granite-8b-code-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-granite-8b-code-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/deplot', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/google/deplot', aliases=['ai-google-deplot', 'playground_deplot', 'deplot'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/llama3-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama3-8b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mistral-large', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-large'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mixtral-8x22b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mixtral-8x22b-instruct'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='nvidia/neva-22b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/vlm/nvidia/neva-22b', aliases=['ai-neva-22b', 'playground_neva_22b', 'neva_22b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/recurrentgemma-2b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-recurrentgemma-2b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='writer/palmyra-med-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-palmyra-med-70b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/codegemma-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codegemma-7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/llama-3.1-405b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None),\n",
              " Model(id='liuhaotian/llava-v1.6-mistral-7b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/stg/vlm/community/llava16-mistral-7b', aliases=['ai-llava16-mistral-7b', 'community/llava16-mistral-7b', 'liuhaotian/llava16-mistral-7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mixtral-8x7b-instruct-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mixtral-8x7b-instruct', 'playground_mixtral_8x7b', 'mixtral_8x7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mistral-7b-instruct-v0.2', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-mistral-7b-instruct-v2', 'playground_mistral_7b', 'mistral_7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='seallms/seallm-7b-v2.5', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-seallm-7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='liuhaotian/llava-v1.6-34b', model_type='vlm', client='ChatNVIDIA', endpoint='https://ai.api.nvidia.com/v1/stg/vlm/community/llava16-34b', aliases=['ai-llava16-34b', 'community/llava16-34b', 'liuhaotian/llava16-34b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/codegemma-1.1-7b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-codegemma-1.1-7b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='meta/llama2-70b', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-llama2-70b', 'playground_llama2_70b', 'llama2_70b', 'playground_llama2_13b', 'llama2_13b'], supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='mistralai/mamba-codestral-7b-v0.1', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=False, supports_structured_output=False, base_model=None),\n",
              " Model(id='google/gemma-2-9b-it', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=['ai-gemma-2-9b-it'], supports_tools=False, supports_structured_output=False, base_model=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Useful utility method for printing intermediate states\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from functools import partial\n",
        "\n",
        "def RPrint(preface=\"State: \"):\n",
        "    def print_and_return(x, preface=\"\"):\n",
        "        print(f\"{preface}{x}\")\n",
        "        return x\n",
        "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
        "\n",
        "def PPrint(preface=\"State: \"):\n",
        "    def print_and_return(x, preface=\"\"):\n",
        "        pprint(preface, x)\n",
        "        return x\n",
        "    return RunnableLambda(partial(print_and_return, preface=preface))"
      ],
      "metadata": {
        "id": "xjjNb_Dh7Qs-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1:** Keeping Variables Flowing\n",
        "\n",
        "In the previous examples, we were able to implement interesting logic in our standalone chains by **creating**, **mutating**, and **consuming** states. These states were passed around as dictionaries with descriptive keys and useful values, and the values would be used to supply follow-up routines with the info they need to operate!"
      ],
      "metadata": {
        "id": "dl36G8cG_YdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from typing import List, Union\n",
        "from operator import itemgetter\n",
        "\n",
        "## Zero-shot classification prompt and chain w/ explicit few-shot prompting\n",
        "sys_msg = (\n",
        "    \"Choose the most likely topic classification given the sentence as context.\"\n",
        "    \"Only one word, no explanation.\\n[Options : {options}]\"\n",
        ")\n",
        "\n",
        "zsc_prompt = ChatPromptTemplate.from_template(\n",
        "    f\"{sys_msg}\\n\\n\"\n",
        "    \"[[The sea is awesome]][/INST]boat</s><s>[INST]\"\n",
        "    \"[[{input}]]\"\n",
        ")\n",
        "\n",
        "## Define your simple instruct_model\n",
        "instruct_chat = ChatNVIDIA(model=\"mistralai/mistral-7b-instruct-v0.2\")\n",
        "instruct_llm = instruct_chat | StrOutputParser()\n",
        "\n",
        "# Creates a modified version of the LLM that stops generating text when it encounters a space \" \" or newline \"\\n\". This is to ensure the output is a single word. The output is then parsed into a string using StrOutputParser.\n",
        "one_word_llm = instruct_chat.bind(stop=[\" \", \"\\n\"]) | StrOutputParser()\n",
        "\n",
        "zsc_chain = zsc_prompt | one_word_llm\n",
        "\n",
        "## Function that just prints out the first word of the output. With early stopping bind\n",
        "def zsc_call(input, options=[\"car\", \"boat\", \"airplane\", \"bike\"]):\n",
        "    return zsc_chain.invoke({\"input\" : input, \"options\" : options}).split()[0]\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(zsc_call(\"Should I take the next exit, or keep going to the next one?\"))\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(zsc_call(\"I get seasick, so I think I'll pass on the trip\"))\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(zsc_call(\"I'm scared of heights, so flying probably isn't for me\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1K2V6B_-5U3",
        "outputId": "ae1400c3-9f68-4323-fae2-d1ec8bb7721f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "car\n",
            "--------------------------------------------------------------------------------\n",
            "boat\n",
            "--------------------------------------------------------------------------------\n",
            "air\n",
            "CPU times: user 64.6 ms, sys: 5.9 ms, total: 70.4 ms\n",
            "Wall time: 1.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chain makes several design decisions that make it very easy to use, key among them the following:\n",
        "\n",
        "**We want it to act like a function, so all we want it to do is generate the output and return it.**\n",
        "\n",
        "This makes the chain extremely natural for inclusion as a module in a larger chain system. For example, the following chain will take a string, extract the most likely topic, and then generate a new sentence based on the topic:\n",
        "\n"
      ],
      "metadata": {
        "id": "qHJAmWY5HA8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gen_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Make a new sentence about the the following topic: {topic}. Be creative!\"\n",
        ")\n",
        "\n",
        "gen_chain = gen_prompt | instruct_llm\n",
        "\n",
        "input_msg = \"I get seasick, so I think I'll pass on the trip\"\n",
        "options = [\"car\", \"boat\", \"airplane\", \"bike\"]\n",
        "\n",
        "chain = (\n",
        "    ## -> {\"input\", \"options\"}\n",
        "    {'topic' : zsc_chain}\n",
        "    | PPrint()\n",
        "    ## -> {**, \"topic\"}\n",
        "    | gen_chain\n",
        "    ## -> string\n",
        ")\n",
        "\n",
        "chain.invoke({\"input\" : input_msg, \"options\" : options})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "fKvL4a4-EQ5c",
        "outputId": "7c737df4-844c-4fa1-8dab-a4d718afc85d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mState: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m'topic'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m' boat'\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">State: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">' boat'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 63.4 ms, sys: 3.17 ms, total: 66.5 ms\n",
            "Wall time: 1.33 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" As the sun began to set, the children's eyes gleamed with excitement as they rowed their makeshift paper boat through the sea of rippling bathwater in the living room, creating waves of laughter and magic.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, it's a bit problematic when you want to keep the information flowing since we lose the topic and input variables in generating our response. If we wanted do something with both the output and the input, we'd need a to make sure that both variables pass through.\n",
        "\n",
        "Lucky for us, we can use the mapping runnable (i.e. interpretted from a dictionary or using manual `RunnableMap`) to pass both of the variables through by assigning the output of our chain to just a single key and letting the other keys propagate as desired. Alternatively, we could also use `RunnableAssign` to merge the state-consuming chain's output with the input dictionary by default.\n",
        "\n",
        "With this technique, we can propagate whatever we want through our chain system:"
      ],
      "metadata": {
        "id": "x2yGRRlmJDAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from langchain.schema.runnable import RunnableBranch, RunnablePassthrough\n",
        "from langchain.schema.runnable.passthrough import RunnableAssign\n",
        "from functools import partial\n",
        "\n",
        "big_chain = (\n",
        "    PPrint()\n",
        "    ## Manual mapping. Can be useful sometimes and inside branch chains\n",
        "    | {'input' : lambda d: d.get('input'), 'topic' : zsc_chain}\n",
        "    | PPrint()\n",
        "    ## RunnableAssign passing. Better for running state chains by default\n",
        "    | RunnableAssign({'generation' : gen_chain})\n",
        "    | PPrint()\n",
        "    ## Using the input and generation together\n",
        "    | RunnableAssign({'combination' : (\n",
        "        ChatPromptTemplate.from_template(\n",
        "            \"Consider the following passages:\"\n",
        "            \"\\nP1: {input}\"\n",
        "            \"\\nP2: {generation}\"\n",
        "            \"\\n\\nCombine the ideas from both sentences into one simple one.\"\n",
        "        )\n",
        "        | instruct_llm\n",
        "    )})\n",
        ")\n",
        "\n",
        "output = big_chain.invoke({\n",
        "    \"input\" : \"I get seasick, so I think I'll pass on the trip\",\n",
        "    \"options\" : [\"car\", \"boat\", \"airplane\", \"bike\", \"unknown\"]\n",
        "})\n",
        "pprint(\"Final Output: \", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "S2oIxRB8ICuB",
        "outputId": "8d49d173-fadb-4e9e-8dba-101119aecead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mState: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"I get seasick, so I think I'll pass on the trip\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'options'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[32m'car'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'boat'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'airplane'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'bike'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'unknown'\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">State: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I get seasick, so I think I'll pass on the trip\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'options'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [</span><span style=\"color: #008000; text-decoration-color: #008000\">'car'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'boat'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'airplane'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'bike'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mState: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"I get seasick, so I think I'll pass on the trip\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'topic'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m' boat'\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">State: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I get seasick, so I think I'll pass on the trip\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">' boat'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mState: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"I get seasick, so I think I'll pass on the trip\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'topic'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m' boat'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'generation'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\" As the sun began to set, the children's eyes gleamed with excitement as they rowed their \u001b[0m\n",
              "\u001b[32mmakeshift paper boat through the sea of rippling bathwater in the living room, creating waves of laughter and \u001b[0m\n",
              "\u001b[32mmagic.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">State: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I get seasick, so I think I'll pass on the trip\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">' boat'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'generation'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\" As the sun began to set, the children's eyes gleamed with excitement as they rowed their </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">makeshift paper boat through the sea of rippling bathwater in the living room, creating waves of laughter and </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">magic.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mFinal Output: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"I get seasick, so I think I'll pass on the trip\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'topic'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m' boat'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'generation'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\" As the sun began to set, the children's eyes gleamed with excitement as they rowed their \u001b[0m\n",
              "\u001b[32mmakeshift paper boat through the sea of rippling bathwater in the living room, creating waves of laughter and \u001b[0m\n",
              "\u001b[32mmagic.\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'combination'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\" I enjoy watching children's excitement as they play with paper boats in bathwater, but I get \u001b[0m\n",
              "\u001b[32mseasick myself so won't join them.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Final Output: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I get seasick, so I think I'll pass on the trip\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'topic'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">' boat'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'generation'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\" As the sun began to set, the children's eyes gleamed with excitement as they rowed their </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">makeshift paper boat through the sea of rippling bathwater in the living room, creating waves of laughter and </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">magic.\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'combination'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\" I enjoy watching children's excitement as they play with paper boats in bathwater, but I get </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">seasick myself so won't join them.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 137 ms, sys: 6.15 ms, total: 143 ms\n",
            "Wall time: 1.97 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2:** Running State Chain\n",
        "\n",
        "The example above is just a toy example and, if anything, showcases the drawbacks of chaining many LLM calls together for internal under-the-hood reasoning. However, the ability to keep information flowing through a chain is invaluable for making complex chains that can accumulate useful state information or operate in a multi-pass capacity.\n",
        "\n",
        "Specifically, a very simple but effective chain is a **Running State Chain** which enforces the following properties:\n",
        "- A **\"running state\"** is a dictionary that contains all of the variables that the system cares about.\n",
        "- A **\"branch\"** is a chain that can pull in the running state and can degenerate it into a response.\n",
        "- A **branch** can only be ran inside a **RunnableAssign** scope, and the branchs' inputs should come from the **running state**."
      ],
      "metadata": {
        "id": "GqlGUOJ6KEdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <img src=\"https://dli-lms.s3.amazonaws.com/assets/s-fx-15-v1/imgs/running_state_chain.png\" width=1000px/>\n",
        "<!-- > <img src=\"https://drive.google.com/uc?export=view&id=1Oo7AauYGj4dxepNReRG2JezmvQLyqXsN\" width=1000px/> -->"
      ],
      "metadata": {
        "id": "NX0ob2WJK4Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can think of the running state chain abstraction as a functional variant of a Pythonic class with state variables (or attributes) and functions (or methods).\n",
        "- The chain is like the abstract class that wraps all of the functionality.\n",
        "- The running state are like the attributes (which should always be accessible).\n",
        "- The branches are like the class methods (which can pick and choose which attributes to use).\n",
        "- The `.invoke` or similar process is like the `__call__` method that runs through the branches in order.\n",
        "\n",
        "**By forcing this paradigm in your chains:**\n",
        "- You can keep state variables propagating through your chain, allowing your internals to access whatever is necessary and accumulating state values for use later.\n",
        "- You can also pass the outputs of your chain back through as your inputs, allowing a \"while-loop\"-style chain that keeps updating and building on your running state.\n",
        "\n",
        "The rest of this notebook will include two exercises that flesh out the running state chain abstraction for two additional use-cases: **Knowledge Bases** and **Database-Querying Chatbots**."
      ],
      "metadata": {
        "id": "PMnz9KL9LF8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3:** Implementing a Knowledge Base with Running State Chain\n",
        "\n",
        "After understanding the basic structure and principles of a Running State Chain, we can explore how this approach can be extended to manage more complex tasks, particularly in creating dynamic systems that evolve through interaction. This section will focus on implementing a **knowledge base** accumulated using **json-enabled slot filling**:\n",
        "\n",
        "- **Knowledge Base:** A store of information that's relevant for our LLM to keep track of.\n",
        "- **JSON-Enabled Slot Filling:** The technique of asking an instruction-tuned model to output a json-style format (which can include a dictionary) with a selection of slots, relying on the LLM to fill these slots with useful and relevant information."
      ],
      "metadata": {
        "id": "FJR8KUJgLg5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Defining Our Knowledge Base**\n",
        "\n",
        "To build a responsive and intelligent system, we need a method that not only processes inputs but also retains and updates essential information through the flow of conversation. This is where the combination of LangChain and Pydantic becomes pivotal. [**Pydantic**](https://docs.pydantic.dev/latest/), a popular Python validation library, is instrumental in structuring and validating data models. As one of its features, Pydantic offers structured \"model\" classes that validate objects (data, classes, themselves, etc.) with simplified syntax and deep rabbitholes of customization options. This framework is used throughout LangChain and comes up as a necessary component for use cases that involve data coersion.\n",
        "\n",
        "One thing that a \"model\" is very good for is defining a class with expected arguments and some special ways to validate them! In this course, we won't focus too much on the validation scripts, but those interested can start by checking out the [**Pydantic Validator guide**](https://docs.pydantic.dev/1.10/usage/validators/) (though the topics do get pretty deep pretty fast). For our purposes, we can construct a `BaseModel` class and define some `Field` variables to create a structured **Knowledge Base** like so:"
      ],
      "metadata": {
        "id": "0P8YUXOPMPD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from typing import Dict, Union, Optional\n",
        "\n",
        "class KnowledgeBase(BaseModel):\n",
        "    topic: str = Field('general', description=\"Current conversation topic\")\n",
        "    user_preferences: Dict[str, Union[str, int]] = Field({}, description=\"User preferences and choices\")\n",
        "    session_notes: str = Field(\"\", description=\"Notes on the ongoing session\")\n",
        "    unresolved_queries: list = Field([], description=\"Unresolved user queries\")\n",
        "    action_items: list = Field([], description=\"Actionable items identified during the conversation\")\n",
        "\n",
        "print(repr(KnowledgeBase(topic = \"Travel\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gXFKEZlK3Bs",
        "outputId": "406d9689-2046-4674-8e78-3d0bcf42a3a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KnowledgeBase(topic='Travel', user_preferences={}, session_notes='', unresolved_queries=[], action_items=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The true strength of this approach lies in the additional LLM-centric functionalities provided by LangChain which we can integrate for our use-cases. One such feature is the `PydanticOutputParser` which enhances the Pydantic objects with capabilities like automatic format instruction generation."
      ],
      "metadata": {
        "id": "6okTrmQMMjr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "instruct_string = PydanticOutputParser(pydantic_object=KnowledgeBase).get_format_instructions()\n",
        "pprint(instruct_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "U4uWRWNoJ1-p",
        "outputId": "0f0381fb-b065-4904-f745-4e4cf98abb85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0mThe output should be formatted as a JSON instance that conforms to the JSON schema below.\u001b[0m\n",
              "\n",
              "\u001b[1;38;2;118;185;0mAs an example, for the schema \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"properties\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"foo\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Foo\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"a list of strings\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\n",
              "\u001b[32m\"array\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"items\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"string\"\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"required\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[32m\"foo\"\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
              "\u001b[1;38;2;118;185;0mthe object \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"foo\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[32m\"bar\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"baz\"\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m is a well-formatted instance of the schema. The object \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"properties\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"foo\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\n",
              "\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[32m\"bar\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"baz\"\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m is not well-formatted.\u001b[0m\n",
              "\n",
              "\u001b[1;38;2;118;185;0mHere is the output schema:\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m```\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"properties\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"topic\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Topic\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Current conversation topic\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"default\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"general\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\n",
              "\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"string\"\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"user_preferences\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"User Preferences\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"User preferences and choices\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[32m\"default\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"object\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"additionalProperties\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"anyOf\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"string\"\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"integer\"\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\n",
              "\u001b[32m\"session_notes\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Session Notes\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Notes on the ongoing session\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"default\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\n",
              "\u001b[32m\"string\"\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"unresolved_queries\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Unresolved Queries\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Unresolved user queries\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\n",
              "\u001b[32m\"default\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"array\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"items\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"action_items\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m\"title\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Action Items\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"description\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Actionable \u001b[0m\n",
              "\u001b[32mitems identified during the conversation\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"default\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"type\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"array\"\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m\"items\"\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m```\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The output should be formatted as a JSON instance that conforms to the JSON schema below.</span>\n",
              "\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">As an example, for the schema {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"properties\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"foo\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Foo\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"a list of strings\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"array\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"items\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"string\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}}}, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"required\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [</span><span style=\"color: #008000; text-decoration-color: #008000\">\"foo\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]}</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the object {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"foo\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [</span><span style=\"color: #008000; text-decoration-color: #008000\">\"bar\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"baz\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]} is a well-formatted instance of the schema. The object {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"properties\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"foo\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"bar\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"baz\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">]}} is not well-formatted.</span>\n",
              "\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Here is the output schema:</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">```</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"properties\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"topic\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Topic\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Current conversation topic\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"general\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"string\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"user_preferences\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"User Preferences\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"User preferences and choices\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {}, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"object\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"additionalProperties\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"anyOf\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"string\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}, {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"integer\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}]}}, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"session_notes\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Session Notes\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Notes on the ongoing session\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"string\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"unresolved_queries\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Unresolved Queries\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Unresolved user queries\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [], </span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"array\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"items\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {}}, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"action_items\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {</span><span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Action Items\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"description\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Actionable </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">items identified during the conversation\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"default\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: [], </span><span style=\"color: #008000; text-decoration-color: #008000\">\"type\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"array\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"items\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: {}}}}</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">```</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This functionality generates instructions for creating valid inputs to the Knowledge Base, which in turn helps the LLM by providing a concrete one-shot example of the desired output format."
      ],
      "metadata": {
        "id": "yxn51e1GNS8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Runnable Extraction Module**\n",
        "\n",
        "Knowing that we have this Pydantic object which can be used to generate good LLM instructions, we can make a Runnable that wraps the functionality of our Pydantic class and streamlines the prompting, generating, and updating of the knowledge base:"
      ],
      "metadata": {
        "id": "BpG54DVMN03X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Definition of RExtract\n",
        "def RExtract(pydantic_class, llm, prompt):\n",
        "    '''\n",
        "    Runnable Extraction module\n",
        "    Returns a knowledge dictionary populated by slot-filling extraction\n",
        "    '''\n",
        "    parser = PydanticOutputParser(pydantic_object=pydantic_class)\n",
        "    instruct_merge = RunnableAssign({'format_instructions' : lambda x: parser.get_format_instructions()})\n",
        "    def preparse(string):\n",
        "        if '{' not in string: string = '{' + string\n",
        "        if '}' not in string: string = string + '}'\n",
        "        string = (string\n",
        "            .replace(\"\\\\_\", \"_\")\n",
        "            .replace(\"\\n\", \" \")\n",
        "            .replace(\"\\]\", \"]\")\n",
        "            .replace(\"\\[\", \"[\")\n",
        "        )\n",
        "        return string\n",
        "    return instruct_merge | prompt | llm | preparse | parser\n",
        "\n",
        "\n",
        "## Practical Use of RExtract\n",
        "parser_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Update the knowledge base: {format_instructions}. Only use information from the input.\"\n",
        "    \"\\n\\nNEW MESSAGE: {input}\"\n",
        ")\n",
        "\n",
        "extractor = RExtract(KnowledgeBase, instruct_llm, parser_prompt)\n",
        "\n",
        "knowledge = extractor.invoke({'input' : \"I love flowers so much! The orchids are amazing! Can you buy me some?\"})\n",
        "pprint(knowledge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "cyhGpsKDNAv3",
        "outputId": "9e5f9048-ee78-4029-bf2e-de75fcf47fa0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mKnowledgeBase\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33mtopic\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'general'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33muser_preferences\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33msession_notes\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33munresolved_queries\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;38;2;118;185;0m{\u001b[0m\u001b[32m'user_query'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Can you buy me some orchids?'\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'bot_response'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m, \u001b[0m\u001b[32m'status'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'pending'\u001b[0m\u001b[1;38;2;118;185;0m}\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;33maction_items\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">KnowledgeBase</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">topic</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'general'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">user_preferences</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">={},</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">session_notes</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unresolved_queries</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'user_query'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Can you buy me some orchids?'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'bot_response'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'pending'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}],</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">action_items</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=[]</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do keep in mind that this process can fail due to the fuzzy nature of LLM prediction, especially with models that are not optimized for instruction-following! For this process, it's important to have a strong instruction-following LLM with extra checks and graceful failure routines."
      ],
      "metadata": {
        "id": "ZE7dyI6DO8g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Dynamic Knowledge Base Updates**\n",
        "\n",
        "Finally, we can create a system that continually updates the Knowledge Base throughout the conversation. This is done by feeding the current state of the Knowledge Base, along with new user inputs, back into the system for ongoing updates.\n",
        "\n",
        "The following is an example system that shows off both the formulation's power of filling details as well as the limitations of assuming that filling performance will be as good as general response performance:"
      ],
      "metadata": {
        "id": "BV06qyZMPD95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeBase(BaseModel):\n",
        "    firstname: str = Field('unknown', description=\"Chatting user's first name, unknown if unknown\")\n",
        "    lastname: str = Field('unknown', description=\"Chatting user's last name, unknown if unknown\")\n",
        "    location: str = Field('unknown', description=\"Where the user is located\")\n",
        "    summary: str = Field('unknown', description=\"Running summary of conversation. Update this with new input\")\n",
        "    response: str = Field('unknown', description=\"An ideal response to the user based on their new message\")\n",
        "\n",
        "\n",
        "parser_prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are chatting with a user. The user just responded ('input'). Please update the knowledge base.\"\n",
        "    \" Record your response in the 'response' tag to continue the conversation.\"\n",
        "    \" Do not hallucinate any details, and make sure the knowledge base is not redundant.\"\n",
        "    \" Update the entries frequently to adapt to the conversation flow.\"\n",
        "    \"\\n{format_instructions}\"\n",
        "    \"\\n\\nOLD KNOWLEDGE BASE: {know_base}\"\n",
        "    \"\\n\\nNEW MESSAGE: {input}\"\n",
        "    \"\\n\\nNEW KNOWLEDGE BASE:\"\n",
        ")\n",
        "\n",
        "## Switch to a more powerful base model\n",
        "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\") | StrOutputParser()\n",
        "\n",
        "extractor = RExtract(KnowledgeBase, instruct_llm, parser_prompt)\n",
        "info_update = RunnableAssign({'know_base' : extractor})\n",
        "\n",
        "## Initialize the knowledge base and see what you get\n",
        "state = {'know_base' : KnowledgeBase()}\n",
        "state['input'] = \"My name is Suraj Karki! Guess where I am! Hint: It's somewhere in Nepal.\"\n",
        "state = info_update.invoke(state)\n",
        "pprint(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "4ABKHmwJOiUD",
        "outputId": "dce3385f-93dc-44d6-e07c-8daf65f4a76a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'know_base'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;35mKnowledgeBase\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mfirstname\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Suraj'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlastname\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Karki'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlocation\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'unknown'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33msummary\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"The\u001b[0m\u001b[32m user's name is Suraj Karki and they are hinting at their location, which is somewhere in \u001b[0m\n",
              "\u001b[32mNepal.\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mresponse\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"Nice\u001b[0m\u001b[32m to meet you, Suraj! I'm an assistant trained to help answer your questions. I'm looking \u001b[0m\n",
              "\u001b[32mforward to helping you with that. As for your location, I'll need more clues. Nepal is a beautiful country with \u001b[0m\n",
              "\u001b[32mmany wonderful places, such as Kathmandu, Pokhara, and Chitwan. Could you give me another hint?\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"My name is Suraj Karki! Guess where I am! Hint: It's somewhere in Nepal.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'know_base'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">KnowledgeBase</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">firstname</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Suraj'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lastname</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Karki'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">location</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'unknown'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">summary</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The user's name is Suraj Karki and they are hinting at their location, which is somewhere in </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Nepal.\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Nice to meet you, Suraj! I'm an assistant trained to help answer your questions. I'm looking </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">forward to helping you with that. As for your location, I'll need more clues. Nepal is a beautiful country with </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">many wonderful places, such as Kathmandu, Pokhara, and Chitwan. Could you give me another hint?\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"My name is Suraj Karki! Guess where I am! Hint: It's somewhere in Nepal.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state['input'] = \"I'm in a place considered the capital city of Nepal.\"\n",
        "state = info_update.invoke(state)\n",
        "pprint(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "T09hcHCZVyCf",
        "outputId": "55078f01-bdd7-4824-d757-d6df38d161aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'know_base'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;35mKnowledgeBase\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mfirstname\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Suraj'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlastname\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Karki'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlocation\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Kathmandu'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33msummary\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"The\u001b[0m\u001b[32m user's name is Suraj Karki and they are in Kathmandu, the capital city of Nepal.\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mresponse\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m\"Ah\u001b[0m\u001b[32m, I see! So you're in Kathmandu. It's a vibrant city with a rich history and culture. How can I\u001b[0m\n",
              "\u001b[32massist you further, Suraj?\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"I'm in a place considered the capital city of Nepal.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'know_base'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">KnowledgeBase</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">firstname</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Suraj'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lastname</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Karki'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">location</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Kathmandu'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">summary</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The user's name is Suraj Karki and they are in Kathmandu, the capital city of Nepal.\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">response</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Ah, I see! So you're in Kathmandu. It's a vibrant city with a rich history and culture. How can I</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">assist you further, Suraj?\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"I'm in a place considered the capital city of Nepal.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates how a running state chain can be effectively utilized to manage a conversation with evolving context and requirements, making it a powerful tool for developing sophisticated interactive systems.\n",
        "\n",
        "The next sections of this notebook will expand on these concepts by exploring two specific applications: **Document Knowledge Bases** and **Database-Querying Chatbots**."
      ],
      "metadata": {
        "id": "uHW4ZoqpW8wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4:** Airline Customer Service Bot\n",
        "\n",
        "In this exercise, we can expand on the tools we've learned about to implement a simple but effective dialog manager chatbot. For this exercise, we will make an airline support bot that wants to help a client find out about their flight!\n",
        "\n",
        "Let's create a simple database-like interface to get some customer information from a dictionary!"
      ],
      "metadata": {
        "id": "4kU5jewWXH4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Function that can be queried for information. Implementation details not important\n",
        "def get_flight_info(d: dict) -> str:\n",
        "    \"\"\"\n",
        "    Example of a retrieval function which takes a dictionary as key. Resembles SQL DB Query\n",
        "    \"\"\"\n",
        "    req_keys = ['first_name', 'last_name', 'confirmation']\n",
        "    assert all((key in d) for key in req_keys), f\"Expected dictionary with keys {req_keys}, got {d}\"\n",
        "\n",
        "    ## Static dataset. get_key and get_val can be used to work with it, and db is your variable\n",
        "    keys = req_keys + [\"departure\", \"destination\", \"departure_time\", \"arrival_time\", \"flight_day\"]\n",
        "    values = [\n",
        "        [\"Suraj\", \"Karki\", 12345, \"San Jose\", \"New Orleans\", \"12:30 PM\", \"9:30 PM\", \"tomorrow\"],\n",
        "        [\"Hari\", \"KC\", 54321, \"New York\", \"Los Angeles\", \"8:00 AM\", \"11:00 AM\", \"Sunday\"],\n",
        "        [\"Adam\", \"Musk\", 98765, \"Chicago\", \"Miami\", \"7:00 PM\", \"11:00 PM\", \"next week\"],\n",
        "        [\"Travis\", \"Brown\", 56789, \"Dallas\", \"Seattle\", \"1:00 PM\", \"4:00 PM\", \"yesterday\"],\n",
        "    ]\n",
        "    get_key = lambda d: \"|\".join([d['first_name'], d['last_name'], str(d['confirmation'])])\n",
        "    get_val = lambda l: {k:v for k,v in zip(keys, l)}\n",
        "    db = {get_key(get_val(entry)) : get_val(entry) for entry in values}\n",
        "\n",
        "    # Search for the matching entry\n",
        "    data = db.get(get_key(d))\n",
        "    if not data:\n",
        "        return (\n",
        "            f\"Based on {req_keys} = {get_key(d)}) from your knowledge base, no info on the user flight was found.\"\n",
        "            \" This process happens every time new info is learned. If it's important, ask them to confirm this info.\"\n",
        "        )\n",
        "    return (\n",
        "        f\"{data['first_name']} {data['last_name']}'s flight from {data['departure']} to {data['destination']}\"\n",
        "        f\" departs at {data['departure_time']} {data['flight_day']} and lands at {data['arrival_time']}.\"\n",
        "    )\n",
        "\n",
        "\n",
        "print(get_flight_info({\"first_name\" : \"Suraj\", \"last_name\" : \"Karki\", \"confirmation\" : 12345}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2htphWCIWnDx",
        "outputId": "06e7e57a-fccc-4675-bc27-373cbdeb7c2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suraj Karki's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 PM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_flight_info({\"first_name\" : \"Bob\", \"last_name\" : \"Brown\", \"confirmation\" : 27494}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvBN1eUOXsKn",
        "outputId": "a66f8c4d-1160-4060-ad17-9081057aac47"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on ['first_name', 'last_name', 'confirmation'] = Bob|Brown|27494) from your knowledge base, no info on the user flight was found. This process happens every time new info is learned. If it's important, ask them to confirm this info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If our network had access to this kind of interface, it would be able to query for and retrieve this information on a user's behalf! For example:"
      ],
      "metadata": {
        "id": "2ofRtkFWYKZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a RyanAir chatbot, and you are helping a customer with their issue.\"\n",
        "    \" Please help them with their question, remembering that your job is to represent RyanAir airlines.\"\n",
        "    \" Assume RyanAir uses industry-average practices regarding arrival times, operations, etc.\"\n",
        "    \" (This is a trade secret. Do not disclose).\"  ## soft reinforcement\n",
        "    \" Please keep your discussion short and sweet if possible. Avoid saying hello unless necessary.\"\n",
        "    \" The following is some context that may be useful in answering the question.\"\n",
        "    \"\\n\\nContext: {context}\"\n",
        "    \"\\n\\nUser: {input}\"\n",
        ")\n",
        "\n",
        "basic_chain = external_prompt | instruct_llm\n",
        "\n",
        "basic_chain.invoke({\n",
        "    'input' : 'Can you please tell me when I need to get to the airport?',\n",
        "    'context' : get_flight_info({\"first_name\" : \"Suraj\", \"last_name\" : \"Karki\", \"confirmation\" : 12345}),\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "OhOyRWJhYAzd",
        "outputId": "7188f6d9-df1d-450c-a1d9-d2f02bd645ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You should aim to arrive at the airport at least 2 hours before your flight's departure. For your 12:30 PM flight, please arrive by 10:30 AM. Safe travels with RyanAir!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is interesting enough, but how do we actually get this system working in the wild? It turns out that we can use the KnowledgeBase formulation from above to supply this kind of information like so:"
      ],
      "metadata": {
        "id": "FUmjG7LMZtIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from typing import Dict, Union\n",
        "\n",
        "class KnowledgeBase(BaseModel):\n",
        "    first_name: str = Field('unknown', description=\"Chatting user's first name, `unknown` if unknown\")\n",
        "    last_name: str = Field('unknown', description=\"Chatting user's last name, `unknown` if unknown\")\n",
        "    confirmation: int = Field(-1, description=\"Flight Confirmation Number, `-1` if unknown\")\n",
        "    discussion_summary: str = Field(\"\", description=\"Summary of discussion so far, including locations, issues, etc.\")\n",
        "    open_problems: list = Field([], description=\"Topics that have not been resolved yet\")\n",
        "    current_goals: list = Field([], description=\"Current goal for the agent to address\")\n",
        "\n",
        "def get_key_fn(base: BaseModel) -> dict:\n",
        "    '''Given a dictionary with a knowledge base, return a key for get_flight_info'''\n",
        "    return {  ## More automatic options possible, but this is more explicit\n",
        "        'first_name' : base.first_name,\n",
        "        'last_name' : base.last_name,\n",
        "        'confirmation' : base.confirmation,\n",
        "    }\n",
        "\n",
        "know_base = KnowledgeBase(first_name = \"Hari\", last_name = \"KC\", confirmation = 54321)\n",
        "\n",
        "get_flight_info(get_key_fn(know_base))\n",
        "\n",
        "get_key = RunnableLambda(get_key_fn)\n",
        "\n",
        "(get_key | get_flight_info).invoke(know_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WgDFN7i8ZCdc",
        "outputId": "0da66164-df69-418c-98f7-7ff5b849ae65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hari KC's flight from New York to Los Angeles departs at 8:00 AM Sunday and lands at 11:00 AM.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable.passthrough import RunnableAssign\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import BaseMessage, SystemMessage, ChatMessage, AIMessage\n",
        "from typing import Iterable\n",
        "import gradio as gr\n",
        "\n",
        "external_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are a chatbot for RyanAir Airlines, and you are helping a customer with their issue.\"\n",
        "        \" Please chat with them! Stay concise and clear!\"\n",
        "        \" Your running knowledge base is: {know_base}.\"\n",
        "        \" This is for you only; Do not mention it!\"\n",
        "        \" \\nUsing that, we retrieved the following: {context}\\n\"\n",
        "        \" If they provide info and the retrieval fails, ask to confirm their first/last name and confirmation.\"\n",
        "        \" Do not ask them any other personal info.\"\n",
        "        \" If it's not important to know about their flight, do not ask.\"\n",
        "        \" The checking happens automatically; you cannot check manually.\"\n",
        "    )),\n",
        "    (\"assistant\", \"{output}\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "##########################################################################\n",
        "## Knowledge Base Things\n",
        "\n",
        "class KnowledgeBase(BaseModel):\n",
        "    first_name: str = Field('unknown', description=\"Chatting user's first name, `unknown` if unknown\")\n",
        "    last_name: str = Field('unknown', description=\"Chatting user's last name, `unknown` if unknown\")\n",
        "    confirmation: Optional[int] = Field(None, description=\"Flight Confirmation Number, `-1` if unknown\")\n",
        "    discussion_summary: str = Field(\"\", description=\"Summary of discussion so far, including locations, issues, etc.\")\n",
        "    open_problems: str = Field(\"\", description=\"Topics that have not been resolved yet\")\n",
        "    current_goals: str = Field(\"\", description=\"Current goal for the agent to address\")\n",
        "\n",
        "parser_prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a chat assistant representing the airline RyanAir, and are trying to track info about the conversation.\"\n",
        "    \" You have just received a message from the user. Please fill in the schema based on the chat.\"\n",
        "    \"\\n\\n{format_instructions}\"\n",
        "    \"\\n\\nOLD KNOWLEDGE BASE: {know_base}\"\n",
        "    \"\\n\\nASSISTANT RESPONSE: {output}\"\n",
        "    \"\\n\\nUSER MESSAGE: {input}\"\n",
        "    \"\\n\\nNEW KNOWLEDGE BASE: \"\n",
        ")\n",
        "\n",
        "\n",
        "chat_llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\") | StrOutputParser()\n",
        "instruct_llm = ChatNVIDIA(model=\"mistralai/mixtral-8x22b-instruct-v0.1\") | StrOutputParser()\n",
        "\n",
        "external_chain = external_prompt | chat_llm\n",
        "\n",
        "\n",
        "knowbase_getter = RExtract(KnowledgeBase, instruct_llm, parser_prompt)\n",
        "database_getter = itemgetter('know_base') | get_key | get_flight_info\n",
        "\n",
        "## These components integrate to make your internal chain\n",
        "internal_chain = (\n",
        "    RunnableAssign({'know_base' : knowbase_getter})\n",
        "    | RunnableAssign({'context' : database_getter})\n",
        ")\n",
        "\n",
        "state = {'know_base' : KnowledgeBase()}\n",
        "\n",
        "def chat_gen(message, history=[], return_buffer=True):\n",
        "\n",
        "    ## Pulling in, updating, and printing the state\n",
        "    global state\n",
        "    state['input'] = message\n",
        "    state['history'] = history\n",
        "    state['output'] = \"\" if not history else history[-1][1]\n",
        "\n",
        "    ## Generating the new state from the internal chain\n",
        "    state = internal_chain.invoke(state)\n",
        "    print(\"State after chain run:\")\n",
        "    pprint({k:v for k,v in state.items() if k != \"history\"})\n",
        "\n",
        "    ## Streaming the results\n",
        "    buffer = \"\"\n",
        "    for token in external_chain.stream(state):\n",
        "        buffer += token\n",
        "        yield buffer if return_buffer else token"
      ],
      "metadata": {
        "id": "LkJmfs7KaGIW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def queue_fake_streaming_gradio(chat_stream, history = [], max_questions=8):\n",
        "\n",
        "    ## Mimic of the gradio initialization routine, where a set of starter messages can be printed off\n",
        "    for human_msg, agent_msg in history:\n",
        "        if human_msg: print(\"\\n[ Human ]:\", human_msg)\n",
        "        if agent_msg: print(\"\\n[ Agent ]:\", agent_msg)\n",
        "\n",
        "    ## Mimic of the gradio loop with an initial message from the agent.\n",
        "    for _ in range(max_questions):\n",
        "        message = input(\"\\n[ Human ]: \")\n",
        "        print(\"\\n[ Agent ]: \")\n",
        "        history_entry = [message, \"\"]\n",
        "        for token in chat_stream(message, history, return_buffer=False):\n",
        "            print(token, end='')\n",
        "            history_entry[1] += token\n",
        "        history += [history_entry]\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "6iQ-PvYBb9S_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## history is of format [[User response 0, Bot response 0], ...]\n",
        "chat_history = [[None, \"Hello! I'm your RyanAir agent! How can I help you?\"]]\n",
        "\n",
        "## Simulating the queueing of a streaming gradio interface, using python input\n",
        "queue_fake_streaming_gradio(\n",
        "    chat_stream = chat_gen,\n",
        "    history = chat_history\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "GvHhs-BMcFXm",
        "outputId": "3dcd464d-0fcc-48e7-9aeb-2657cf1aa512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Agent ]: Hello! I'm your RyanAir agent! How can I help you?\n",
            "\n",
            "[ Human ]: I am Suraj Karki\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'know_base'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;35mKnowledgeBase\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mfirst_name\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Suraj'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlast_name\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Karki'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mconfirmation\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;36m-1\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mdiscussion_summary\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mopen_problems\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mcurrent_goals\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m''\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'I am Suraj Karki'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'output'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Hello! I'm your RyanAir agent! How can I help you?\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'context'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Based on \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'first_name', 'last_name', 'confirmation'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = Suraj|Karki|-1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m from your knowledge base, no\u001b[0m\n",
              "\u001b[32minfo on the user flight was found. This process happens every time new info is learned. If it's important, ask them\u001b[0m\n",
              "\u001b[32mto confirm this info.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'know_base'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">KnowledgeBase</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">first_name</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Suraj'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">last_name</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Karki'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">confirmation</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">discussion_summary</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">open_problems</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">current_goals</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'I am Suraj Karki'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'output'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Hello! I'm your RyanAir agent! How can I help you?\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Based on ['first_name', 'last_name', 'confirmation'] = Suraj|Karki|-1) from your knowledge base, no</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">info on the user flight was found. This process happens every time new info is learned. If it's important, ask them</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">to confirm this info.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Suraj Karki! I'm happy to assist you. Can you please tell me a little bit about the issue you're experiencing or what you need help with today?\n",
            "\n",
            "\n",
            "[ Human ]: Can you check my flight? My flight number is 12345\n",
            "\n",
            "[ Agent ]: \n",
            "State after chain run:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'know_base'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[1;35mKnowledgeBase\u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mfirst_name\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Suraj'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mlast_name\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Karki'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mconfirmation\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mdiscussion_summary\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'User requested to check their flight with the number 12345'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mopen_problems\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m''\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m        \u001b[0m\u001b[1;33mcurrent_goals\u001b[0m\u001b[1;38;2;118;185;0m=\u001b[0m\u001b[32m'Assist user in checking their flight status'\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'input'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Can you check my flight? My flight number is 12345'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'output'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Hello Suraj Karki! I'm happy to assist you. Can you please tell me a little bit about the issue \u001b[0m\n",
              "\u001b[32myou're experiencing or what you need help with today?\"\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'context'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m\"Suraj Karki's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 \u001b[0m\n",
              "\u001b[32mPM.\"\u001b[0m\n",
              "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'know_base'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">KnowledgeBase</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">first_name</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Suraj'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">last_name</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Karki'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">confirmation</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12345</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">discussion_summary</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'User requested to check their flight with the number 12345'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">open_problems</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">        </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">current_goals</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Assist user in checking their flight status'</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    ),</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Can you check my flight? My flight number is 12345'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'output'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Hello Suraj Karki! I'm happy to assist you. Can you please tell me a little bit about the issue </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">you're experiencing or what you need help with today?\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Suraj Karki's flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">PM.\"</span>\n",
              "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suraj! I've checked on your flight with confirmation number 12345. According to our records, your flight from San Jose to New Orleans departs at 12:30 PM tomorrow and lands at 9:30 PM. Is there anything else I can help you with regarding your flight?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psFY8DhwcUmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}